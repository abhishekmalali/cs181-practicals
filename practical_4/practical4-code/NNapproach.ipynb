{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn.neural_network in sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn.neural_network\n",
      "\n",
      "FILE\n",
      "    /Users/abhishek/anaconda/lib/python2.7/site-packages/sklearn/neural_network/__init__.py\n",
      "\n",
      "DESCRIPTION\n",
      "    The :mod:`sklearn.neural_network` module includes models based on neural\n",
      "    networks.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    rbm\n",
      "\n",
      "CLASSES\n",
      "    sklearn.base.BaseEstimator(__builtin__.object)\n",
      "        sklearn.neural_network.rbm.BernoulliRBM(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      "    sklearn.base.TransformerMixin(__builtin__.object)\n",
      "        sklearn.neural_network.rbm.BernoulliRBM(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      "    \n",
      "    class BernoulliRBM(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      "     |  Bernoulli Restricted Boltzmann Machine (RBM).\n",
      "     |  \n",
      "     |  A Restricted Boltzmann Machine with binary visible units and\n",
      "     |  binary hiddens. Parameters are estimated using Stochastic Maximum\n",
      "     |  Likelihood (SML), also known as Persistent Contrastive Divergence (PCD)\n",
      "     |  [2].\n",
      "     |  \n",
      "     |  The time complexity of this implementation is ``O(d ** 2)`` assuming\n",
      "     |  d ~ n_features ~ n_components.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <rbm>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_components : int, optional\n",
      "     |      Number of binary hidden units.\n",
      "     |  \n",
      "     |  learning_rate : float, optional\n",
      "     |      The learning rate for weight updates. It is *highly* recommended\n",
      "     |      to tune this hyper-parameter. Reasonable values are in the\n",
      "     |      10**[0., -3.] range.\n",
      "     |  \n",
      "     |  batch_size : int, optional\n",
      "     |      Number of examples per minibatch.\n",
      "     |  \n",
      "     |  n_iter : int, optional\n",
      "     |      Number of iterations/sweeps over the training dataset to perform\n",
      "     |      during training.\n",
      "     |  \n",
      "     |  verbose : int, optional\n",
      "     |      The verbosity level. The default, zero, means silent mode.\n",
      "     |  \n",
      "     |  random_state : integer or numpy.RandomState, optional\n",
      "     |      A random number generator instance to define the state of the\n",
      "     |      random permutations generator. If an integer is given, it fixes the\n",
      "     |      seed. Defaults to the global numpy random number generator.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  intercept_hidden_ : array-like, shape (n_components,)\n",
      "     |      Biases of the hidden units.\n",
      "     |  \n",
      "     |  intercept_visible_ : array-like, shape (n_features,)\n",
      "     |      Biases of the visible units.\n",
      "     |  \n",
      "     |  components_ : array-like, shape (n_components, n_features)\n",
      "     |      Weight matrix, where n_features in the number of\n",
      "     |      visible units and n_components is the number of hidden units.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  \n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.neural_network import BernoulliRBM\n",
      "     |  >>> X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
      "     |  >>> model = BernoulliRBM(n_components=2)\n",
      "     |  >>> model.fit(X)\n",
      "     |  BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=2, n_iter=10,\n",
      "     |         random_state=None, verbose=0)\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  \n",
      "     |  [1] Hinton, G. E., Osindero, S. and Teh, Y. A fast learning algorithm for\n",
      "     |      deep belief nets. Neural Computation 18, pp 1527-1554.\n",
      "     |      http://www.cs.toronto.edu/~hinton/absps/fastnc.pdf\n",
      "     |  \n",
      "     |  [2] Tieleman, T. Training Restricted Boltzmann Machines using\n",
      "     |      Approximations to the Likelihood Gradient. International Conference\n",
      "     |      on Machine Learning (ICML) 2008\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BernoulliRBM\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_components=256, learning_rate=0.1, batch_size=10, n_iter=10, verbose=0, random_state=None)\n",
      "     |  \n",
      "     |  fit(self, X, y=None)\n",
      "     |      Fit the model to the data X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : BernoulliRBM\n",
      "     |          The fitted model.\n",
      "     |  \n",
      "     |  gibbs(self, v)\n",
      "     |      Perform one Gibbs sampling step.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      v : array-like, shape (n_samples, n_features)\n",
      "     |          Values of the visible layer to start from.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      v_new : array-like, shape (n_samples, n_features)\n",
      "     |          Values of the visible layer after one Gibbs step.\n",
      "     |  \n",
      "     |  partial_fit(self, X, y=None)\n",
      "     |      Fit the model to the data X which should contain a partial\n",
      "     |      segment of the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : BernoulliRBM\n",
      "     |          The fitted model.\n",
      "     |  \n",
      "     |  score_samples(self, X)\n",
      "     |      Compute the pseudo-likelihood of X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} shape (n_samples, n_features)\n",
      "     |          Values of the visible layer. Must be all-boolean (not checked).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pseudo_likelihood : array-like, shape (n_samples,)\n",
      "     |          Value of the pseudo-likelihood (proxy for likelihood).\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is not deterministic: it computes a quantity called the\n",
      "     |      free energy on X, then on a randomly corrupted version of X, and\n",
      "     |      returns the log of the logistic function of the difference.\n",
      "     |  \n",
      "     |  transform(self, X)\n",
      "     |      Compute the hidden layer activation probabilities, P(h=1|v=X).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} shape (n_samples, n_features)\n",
      "     |          The data to be transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      h : array, shape (n_samples, n_components)\n",
      "     |          Latent representations of the data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep: boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The former have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |  \n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |      \n",
      "     |      Fits transformer to X and y with optional parameters fit_params\n",
      "     |      and returns a transformed version of X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : numpy array of shape [n_samples, n_features]\n",
      "     |          Training set.\n",
      "     |      \n",
      "     |      y : numpy array of shape [n_samples]\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      "     |          Transformed array.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['BernoulliRBM']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sklearn.neural_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
